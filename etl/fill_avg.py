"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è –ë–î –¥–∞–Ω–Ω—ã–º–∏ –æ —Å—Ä–µ–¥–Ω–µ–π –º–µ—Å—è—á–Ω–æ–π –ó–ü –ø–æ –ø–æ–ª—É –∏ —Ä–æ–¥—É –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
–°–∫–∞—á–∞–ª –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—é–¥–∞: https://rshiny.ilo.org/dataexplorer06/?lang=en&segment=indicator&id=EAR_4MTH_SEX_OCU_CUR_NB_A#
–§–∞–π–ª –≤ data: EAR_4MTH_SEX_OCU_CUR_NB_A-filtered-2025-11-01
"""

import asyncio
import csv
from pathlib import Path
from typing import Dict, List, Sequence, Union, cast

from src.core.config.logging import setup_logger_to_file
from src.core.database.db_config import AsyncSessionLocal
from src.ms_location.dto import CountryGetDTO
from src.ms_location.models import CountryModel
from src.ms_metric.dto import (
    MetricInfoCreateDTO,
    MetricPeriodCreateDTO,
    MetricSeriesCreateDTO,
)
from src.ms_metric.enums import CategoryMetricEnum, PeriodTypeEnum, TypeDataEnum
from src.ms_metric.models import (
    MetricDataModel,
    MetricInfoModel,
    MetricPeriodModel,
    MetricSeriesModel,
)


logger = setup_logger_to_file()

# === –¢—Ä–µ–±—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ===
REQUIRED_COLUMNS = {
    "ref_area.label",
    "source.label",
    "indicator.label",
    "sex.label",
    "classif1.label",
    "classif2.label",
    "time",
    "obs_value",
    "obs_status.label",
    "note_classif.label",
    "note_indicator.label",
    "note_source.label",
}

# === 1. –û–ø–∏—Å–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ CSV –≤ —Ñ–∞–π–ª–µ ===
csv_columns_description = {
    "ref_area.label": "–ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã (–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è country_id –≤ CountryModel).",
    "source.label": "–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–ø–æ–ª–Ω—è–µ—Ç source_name –≤ MetricModel).",
    "indicator.label": "–ù–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (MetricModel.name / slug).",
    "sex.label": "–ü–æ–ª ('Total', 'Male', 'Female' –∏ —Ç.–¥.) ‚Äî –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ add_info.",
    "classif1.label": "–ü–µ—Ä–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ—Ñ–µ—Å—Å–∏—è –∏–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—è) ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ add_info.",
    "classif2.label": "–í—Ç–æ—Ä–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, —á–∞—Å—Ç–æ –µ–¥–∏–Ω–∏—Ü–∞ –∏–∑–º–µ—Ä–µ–Ω–∏—è ‚Äî –∏–¥—ë—Ç –≤ MetricModel.unit_format.",
    "time": "–ì–æ–¥ (–∏–ª–∏ –ø–µ—Ä–∏–æ–¥) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è MetricPeriodModel.period_year.",
    "obs_value": "–ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ MetricDataModel.value_float.",
    "obs_status.label": "–°—Ç–∞—Ç—É—Å –Ω–∞–±–ª—é–¥–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Break in series') ‚Äî add_info['obs_status'].",
    "note_indicator.label": "–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ –∫ –ø–æ–∫–∞–∑–∞—Ç–µ–ª—é ‚Äî add_info['note_indicator'].",
    "note_source.label": "–û–ø–∏—Å–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ ‚Äî add_info['note_source'] –∏–ª–∏ MetricModel.source_url.",
}


# === 2. –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω ===
COUNTRY_MAP = {
    "bolivia (plurinational state of)": ["Bolivia"],
    "brunei darussalam": ["Brunei"],
    "c√¥te d'ivoire": ["Ivory Coast"],
    "hong kong, china": ["Hong Kong"],
    "lao people's democratic republic": ["Laos"],
    "macao, china": ["Macao"],
    "occupied palestinian territory": ["Palestine"],
    "republic of korea": ["South Korea"],
    "republic of moldova": ["Moldova"],
    "russian federation": ["Russia"],
    "tanzania, united republic of": ["Tanzania"],
    "united kingdom of great britain and northern ireland": ["Great Britain", "Ireland"],
    "united states of america": ["USA"],
    "venezuela (bolivarian republic of)": ["Venezuela"],
    "viet nam": ["Vietnam"],
}


# === –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã CSV ===
def validate_csv_structure(header: Union[Sequence[str], List[str]]) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å –≤ CSV.
    –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –±—Ä–æ—Å–∞–µ—Ç ValueError —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º.
    """

    header_set = set(col.strip() for col in header)
    missing = REQUIRED_COLUMNS - header_set
    extra = header_set - REQUIRED_COLUMNS

    if missing:
        msg = f"‚ùå –í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(sorted(missing))}"
        logger.error(msg)
        raise ValueError(msg)

    if extra:
        logger.warning(f"‚ö†Ô∏è –í CSV –Ω–∞–π–¥–µ–Ω—ã –ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã): {', '.join(sorted(extra))}")

    logger.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ ‚Äî –≤—Å–µ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.")


# === –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ===
async def import_csv(file_path: Path, batch_size: int = 50):
    """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ CSV –≤ –ë–î.

    –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞:
    1. –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω—É -> country_id
    2. –°–æ–∑–¥–∞—ë–º (–∏–ª–∏ –±–µ—Ä—ë–º) –º–µ—Ç—Ä–∏–∫—É MetricModel
    3. –°–æ–∑–¥–∞—ë–º (–∏–ª–∏ –±–µ—Ä—ë–º) –ø–µ—Ä–∏–æ–¥ MetricPeriodModel
    4. –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å MetricDataModel
    """

    # –°–æ–∑–¥–∞—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Å–µ—Å—Å–∏—é
    async with AsyncSessionLocal() as async_session:

        # –ö—ç—à
        metric_cache: Dict[str, MetricInfoModel] = {}
        series_cache: Dict[str, MetricSeriesModel] = {}
        period_cache: Dict[str, MetricPeriodModel] = {}
        country_cache: Dict[str, int] = {}

        buffer: List[MetricDataModel] = []  # –ë—É—Ñ–µ—Ä –¥–ª—è batch insert
        total_inserted = 0

        # –û—Ç–∫—Ä—ã–≤–∞—é CSV —Ñ–∞–π–ª
        with open(file_path, encoding="utf-8") as f:

            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (–∑–∞–≥–æ–ª–æ–≤–∫–∏) –∏ —á–∏—Å—Ç–∏–º –∏—Ö
            raw_header = f.readline().strip().split(",")
            header = [col.strip().replace("\ufeff", "").replace('"', "").replace("'", "") for col in raw_header]

            # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ ===
            validate_csv_structure(header)

            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞—ë–º DictReader —Å —á–∏—Å—Ç—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
            f.seek(0)
            reader = csv.DictReader(f, fieldnames=header)
            next(reader)  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (—É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞)

            # –ü—Ä–æ—Ö–æ–∂—É—Å—å –ø–æ —Å—Ç—Ä–æ–∫–∞–º —Ñ–∞–π–ª–∞
            for idx, row in enumerate(reader, 1):
                # logger.info(f"\nüîπ {idx}. {row['indicator.label']} ‚Äî {row['ref_area.label']}")

                # === –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞–Ω—É ===
                raw_country = row["ref_area.label"].strip().lower()
                country_names = COUNTRY_MAP.get(raw_country, [row["ref_area.label"].strip()])

                # –ü—Ä–æ—Ö–æ–∂—É—Å—å –ø–æ —Å—Ç—Ä–∞–Ω–∞–º —Å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏
                for country_name in country_names:

                    # –ö—ç—à —Å—Ç—Ä–∞–Ω
                    if country_name in country_cache:
                        country_id = country_cache[country_name]
                    else:
                        country = await CountryModel.get(async_session, CountryGetDTO(name_eng=country_name))
                        if not country:
                            logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∞ '{country_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫.")
                            continue
                        country_id = cast(int, country.id)
                        country_cache[country_name] = country_id

                    # === –°–æ–∑–¥–∞—é –º–µ—Ç—Ä–∏–∫—É ===
                    slug = row["indicator.label"].lower().replace(" ", "_").strip()
                    unique_key_metric = slug

                    # –ö—ç—à –º–µ—Ç—Ä–∏–∫
                    metric = metric_cache.get(unique_key_metric)
                    if not metric:
                        metric_dto_create = MetricInfoCreateDTO(
                            slug=slug,
                            name="–°—Ä–µ–¥–Ω–∏–π –µ–∂–µ–º–µ—Å—è—á–Ω—ã–π –∑–∞—Ä–∞–±–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –ø–æ –ø–æ–ª—É –∏ —Ä–æ–¥—É –∑–∞–Ω—è—Ç–∏–π",
                            description="–°—Ä–µ–¥–Ω–∏–π –µ–∂–µ–º–µ—Å—è—á–Ω—ã–π –∑–∞—Ä–∞–±–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç–Ω–∏–∫–æ–≤ –ø–æ –ø–æ–ª—É –∏ —Ä–æ–¥—É –∑–∞–Ω—è—Ç–∏–π",
                            category=CategoryMetricEnum.ECONOMY,
                            source_name="ILOSTAT data explorer",
                            source_url="https://rshiny.ilo.org/dataexplorer06/?lang=en&segment=indicator&id=EAR_4MTH_SEX_OCU_CUR_NB_A",
                            type_data=TypeDataEnum.FLOAT,
                            is_active=True,
                            add_info=None,
                        )
                        metric = await MetricInfoModel.get_or_create(async_session, metric_dto_create)
                        metric_id = cast(int, metric.id)
                        metric_cache[unique_key_metric] = metric

                    # === –°–æ–∑–¥–∞—é —Å–µ—Ä–∏—é ===
                    gender = row["sex.label"]
                    unit = row["classif2.label"].strip()
                    professions = row["classif1.label"]
                    unique_key_series = f"{metric_id} {gender} {unit} {professions}"

                    # –ö—ç—à –º–µ—Ç—Ä–∏–∫
                    series = series_cache.get(unique_key_series)
                    if not series:
                        series_dto_create = MetricSeriesCreateDTO(
                            metric_id=metric_id,
                            is_active=True,
                            add_info={"unit": unit, "gender": gender, "professions": professions},
                        )
                        series = await MetricSeriesModel.get_or_create(async_session, series_dto_create)
                        series_id = cast(int, series.id)
                        series_cache[unique_key_series] = series

                    # === –°–æ–∑–¥–∞—é –ø–µ—Ä–∏–æ–¥ –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏===
                    year = int(row["time"])
                    unique_key_period = f"{metric_id}_{series_id}_{year}"

                    # –ö—ç—à –ø–µ—Ä–∏–æ–¥–∞
                    period = period_cache.get(unique_key_period)
                    if not period:
                        period_dto_create = MetricPeriodCreateDTO(
                            series_id=series_id,
                            period_type=PeriodTypeEnum.YEARLY,
                            period_year=year,
                            add_info=None,
                        )
                        period = await MetricPeriodModel.get_or_create(async_session, period_dto_create)
                        period_id = cast(int, period.id)
                        period_cache[unique_key_period] = period

                    # === –°–æ–∑–¥–∞—é –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ ===
                    try:
                        value = float(row["obs_value"]) if row["obs_value"] else None
                    except ValueError:
                        logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ obs_value: {row['obs_value']}")
                        continue

                    buffer.append(
                        MetricDataModel(
                            series_id=series_id,
                            period_id=period_id,
                            country_id=country_id,
                            value_float=value,
                            add_info={
                                "obs_status": row["obs_status.label"],
                                "note_classif": row["note_classif.label"],
                                "note_indicator": row["note_indicator.label"],
                                "note_source": row["note_source.label"],
                            },
                        )
                    )

                    # === –ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ ===
                    if len(buffer) >= batch_size:
                        async_session.add_all(buffer)
                        await async_session.commit()
                        total_inserted += len(buffer)
                        logger.info(f"üíæ –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ ‚Äî {total_inserted} –∑–∞–ø–∏—Å–µ–π")
                        buffer.clear()

        # –§–∏–Ω–∞–ª—å–Ω—ã–π commit –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–ø–∏—Å–µ–π
        if buffer:
            async_session.add_all(buffer)
            await async_session.commit()
            total_inserted += len(buffer)
            logger.info(f"üíæ –§–∏–Ω–∞–ª—å–Ω—ã–π commit ‚Äî {total_inserted} –∑–∞–ø–∏—Å–µ–π")

        logger.info(f"\n‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_inserted} –∑–∞–ø–∏—Å–µ–π.")


if __name__ == "__main__":
    asyncio.run(import_csv(Path("data/EAR_4MTH_SEX_OCU_CUR_NB_A-filtered-2025-11-01.csv")))
