# etl/fill_labout_comes_by_sex.py
"""
–ó–∞–ø–æ–ª–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø–æ
Labour market outcomes of immigrants - Employment, unemployment, and participation rates by sex
—Å–∞–π—Ç: https://data-explorer.oecd.org/vis?lc=en&df[ds]=DisseminateFinalDMZ&df[id]=DSD_MIG%40DF_MIG_NUP_SEX&df[ag]=OECD.ELS.IMD&df[vs]=1.0&dq=..A.EMP_WAP....&pd=2020%2C2024&to[TIME_PERIOD]=false
—Ñ–∞–π–ª: OECD.ELS.IMD,DSD_MIG@DF_MIG_NUP_SEX,1.0+..A.EMP_WAP....

–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö OECD –º–∏–≥—Ä–∞—Ü–∏–∏ –≤ –ë–î.
–ü–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π ‚Äî —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω —Å CountryModel.
"""

import asyncio
import csv
from pathlib import Path
from typing import Dict, List, Literal, Sequence, Union, cast

import pandas as pd
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.config.logging import setup_logger_to_file
from src.core.database.db_config import AsyncSessionLocal
from src.core.utils.country_companator import compare_country_list_by_column
from src.ms_location.dto import CountryGetDTO
from src.ms_location.models import CountryModel
from src.ms_metric.dto import (
    MetricInfoCreateDTO,
    MetricPeriodCreateDTO,
    MetricSeriesCreateDTO,
)
from src.ms_metric.enums import CategoryMetricEnum, PeriodTypeEnum, TypeDataEnum
from src.ms_metric.models import (
    MetricDataModel,
    MetricInfoModel,
    MetricPeriodModel,
    MetricSeriesModel,
)


logger = setup_logger_to_file()


# ============================================================
#                    CONFIG
# ============================================================
# –£–∫–∞–∂–∏ —Ç—Ä–µ–±—É–µ–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ CSV —Ñ–∞–π–ª–µ
REQUIRED_COLUMNS = {
    "STRUCTURE",
    "STRUCTURE_ID",
    "STRUCTURE_NAME",
    "ACTION",
    "REF_AREA",
    "Reference area",
    "CITIZENSHIP",
    "Citizenship",
    "FREQ",
    "Frequency of observation",
    "MEASURE",
    "Measure",
    "SEX",
    "Sex",
    "BIRTH_PLACE",
    "Place of birth",
    "EDUCATION_LEV",
    "Education level",
    "UNIT_MEASURE",
    "Unit of measure",
    "TIME_PERIOD",
    "Time period",
    "OBS_VALUE",
    "OBS_STATUS",
    "Observation status",
    "UNIT_MULT",
    "Unit multiplier",
    "DECIMALS",
    "Decimals",
}

# –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–¥–æ–≤ –≤ CSV -> —Å–ø–∏—Å–æ–∫ ISO Alpha-3
COUNTRY_MAP = {
    "EU27_2020": [
        "AUT",
        "BEL",
        "BGR",
        "HRV",
        "CYP",
        "CZE",
        "DNK",
        "EST",
        "FIN",
        "FRA",
        "DEU",
        "GRC",
        "HUN",
        "IRL",
        "ITA",
        "LVA",
        "LTU",
        "LUX",
        "MLT",
        "NLD",
        "POL",
        "PRT",
        "ROU",
        "SVK",
        "SVN",
        "ESP",
        "SWE",
    ],
    "AUS": ["AUS"],
}


# ============================================================
#                    –§—É–Ω–∫—Ü–∏–∏
# ============================================================
def validate_csv_structure(header: Union[Sequence[str], List[str]]) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –µ—Å—Ç—å –≤ CSV. –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç ‚Äî –±—Ä–æ—Å–∞–µ—Ç ValueError —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º."""

    header_set = set(col.strip() for col in header)
    missing = REQUIRED_COLUMNS - header_set
    extra = header_set - REQUIRED_COLUMNS

    if missing:
        msg = f"‚ùå –í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(sorted(missing))}"
        logger.error(msg)
        raise ValueError(msg)

    if extra:
        logger.warning(f"‚ö†Ô∏è –í CSV –Ω–∞–π–¥–µ–Ω—ã –ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ (–æ–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω—ã): {', '.join(sorted(extra))}")

    logger.info("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ CSV –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞ ‚Äî –≤—Å–µ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.")


async def get_or_create_metric_cached(
    cache: Dict[str, MetricInfoModel],
    unique_key: str,
    session: AsyncSession,
    slug: str,
    name: str,
    description: str,
    category: CategoryMetricEnum,
    source_name: str,
    source_url: str,
    type_data: TypeDataEnum,
    add_info: dict,
) -> MetricInfoModel:

    if unique_key in cache:
        return cache[unique_key]

    metric = await MetricInfoModel.get_or_create(
        session,
        MetricInfoCreateDTO(
            slug=slug,
            name=name,
            description=description,
            category=category,
            source_name=source_name,
            source_url=source_url,
            type_data=type_data,
            add_info=add_info,
            is_active=True,
        ),
    )
    cache[unique_key] = metric
    return metric


async def get_or_create_series_cached(
    cache: Dict[str, MetricSeriesModel],
    unique_key: str,
    session: AsyncSession,
    metric_id: int,
    add_info: dict,
) -> MetricSeriesModel:

    if unique_key in cache:
        return cache[unique_key]

    series = await MetricSeriesModel.get_or_create(
        session,
        MetricSeriesCreateDTO(metric_id=metric_id, add_info=add_info, is_active=True),
    )
    cache[unique_key] = series
    return series


async def get_or_create_period_cached(
    cache: Dict[str, MetricPeriodModel],
    unique_key: str,
    session: AsyncSession,
    series_id: int,
    period_type: PeriodTypeEnum,
    year: int,
) -> MetricPeriodModel:
    if unique_key in cache:
        return cache[unique_key]

    period = await MetricPeriodModel.get_or_create(
        session,
        MetricPeriodCreateDTO(
            series_id=series_id,
            period_type=period_type,
            period_year=year,
            add_info=None,
        ),
    )
    cache[unique_key] = period
    return period


# ============================================================
#                 –û–°–ù–û–í–ù–û–ô –ò–ú–ü–û–†–¢ CAR
# ============================================================
async def import_csv(session: AsyncSession, file_path: Path, batch_size: int = 50):
    """–ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ –∏–∑ CSV –≤ –ë–î.

    –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞:
    1. –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç—Ä–∞–Ω—É
    2. –°–æ–∑–¥–∞—ë–º (–∏–ª–∏ –±–µ—Ä—ë–º) –º–µ—Ç—Ä–∏–∫—É MetricInfoModel
    3. –°–æ–∑–¥–∞—ë–º (–∏–ª–∏ –±–µ—Ä—ë–º) —Å–µ—Ä–∏—é MetricSeriesModel
    4. –°–æ–∑–¥–∞—ë–º (–∏–ª–∏ –±–µ—Ä—ë–º) –ø–µ—Ä–∏–æ–¥ MetricPeriodModel
    5. –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å MetricDataModel
    """

    # –ö—ç—à
    country_cache: Dict[str, int] = {}
    metric_cache: Dict[str, MetricInfoModel] = {}
    series_cache: Dict[str, MetricSeriesModel] = {}
    period_cache: Dict[str, MetricPeriodModel] = {}

    buffer: List[MetricDataModel] = []  # –ë—É—Ñ–µ—Ä –¥–ª—è batch insert
    total_inserted = 0

    # –û—Ç–∫—Ä—ã–≤–∞—é CSV —Ñ–∞–π–ª
    with open(file_path, encoding="utf-8") as f:

        # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É (–∑–∞–≥–æ–ª–æ–≤–∫–∏) –∏ —á–∏—Å—Ç–∏–º –∏—Ö
        raw_header = f.readline().strip().split(",")
        header = [col.strip().replace("\ufeff", "").replace('"', "").replace("'", "") for col in raw_header]

        # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ ===
        validate_csv_structure(header)

        # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –≤ –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞—ë–º DictReader —Å —á–∏—Å—Ç—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
        f.seek(0)
        reader = csv.DictReader(f, fieldnames=header)
        next(reader)  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É-–∑–∞–≥–æ–ª–æ–≤–æ–∫ (—É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞)

        # –ü—Ä–æ—Ö–æ–∂—É—Å—å –ø–æ —Å—Ç—Ä–æ–∫–∞–º —Ñ–∞–π–ª–∞
        for row in reader:

            # --- –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω ---
            country_from_file = row["REF_AREA"].strip()
            country_iso_alpha3_codes = COUNTRY_MAP.get(country_from_file, [country_from_file])

            # –ü—Ä–æ—Ö–æ–∂—É—Å—å –ø–æ —Å—Ç—Ä–∞–Ω–∞–º —Å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏
            for country_code in country_iso_alpha3_codes:

                # === –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä–∞–Ω—É ===
                if country_code in country_cache:
                    country_id = country_cache[country_code]
                else:
                    country_obj = await CountryModel.get(session, CountryGetDTO(iso_alpha_3=country_code))
                    if not country_obj:
                        logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–∞–Ω–∞ '{country_code}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø—Ä–æ–ø—É—Å–∫.")
                        continue
                    country_id = cast(int, country_obj.id)
                    country_cache[country_code] = country_id

                # === –°–æ–∑–¥–∞—é –º–µ—Ç—Ä–∏–∫—É: –æ–ø—Ä–µ–¥–µ–ª—è—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∏ –≤—ã–∑—ã–≤–∞—é –º–µ—Ç–æ–¥ get_or_create_metric_cached ===
                slug = row["STRUCTURE_NAME"].lower().replace(" ", "_").strip()
                unique_key_metric = slug
                name = row["STRUCTURE_NAME"]
                description = row["STRUCTURE_NAME"]
                category = CategoryMetricEnum.ECONOMY
                source_name = "OECD Data Explorer"
                source_url = "https://data-explorer.oecd.org/vis?lc=en&df[ds]=DisseminateFinalDMZ&df[id]=DSD_MIG%40DF_MIG_NUP_SEX&df[ag]=OECD.ELS.IMD&df[vs]=1.0&dq=..A.EMP_WAP....&pd=2020%2C2024&to[TIME_PERIOD]=false"
                type_data = TypeDataEnum.FLOAT
                add_info = {
                    "citizenship": row["Citizenship"],
                    "frequency_of_observation": row["Frequency of observation"],
                    "measure": row["Measure"],
                    "education_level": row["Education level"],
                    "unit_of_measure": row["Unit of measure"],
                }

                metric = await get_or_create_metric_cached(
                    cache=metric_cache,
                    unique_key=unique_key_metric,
                    session=session,
                    slug=slug,
                    name=name,
                    description=description,
                    category=category,
                    source_name=source_name,
                    source_url=source_url,
                    type_data=type_data,
                    add_info=add_info,
                )
                metric_id = cast(int, metric.id)

                # === –°–æ–∑–¥–∞—é —Å–µ—Ä–∏—é: –æ–ø—Ä–µ–¥–µ–ª—è—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∏ –≤—ã–∑—ã–≤–∞—é –º–µ—Ç–æ–¥ get_or_create_series_cached ===
                gender = row["Sex"]
                unit = row["Unit multiplier"].lower().strip()
                place_of_birth = row["Place of birth"].lower().strip()
                unique_key_series = f"{metric_id} {gender} {unit} {place_of_birth}"
                add_info = {
                    "gender": gender,
                    "unit": unit,
                    "place_of_birth": place_of_birth,
                }

                series = await get_or_create_series_cached(
                    cache=series_cache,
                    unique_key=unique_key_series,
                    session=session,
                    metric_id=metric_id,
                    add_info=add_info,
                )
                series_id = cast(int, series.id)

                # === –°–æ–∑–¥–∞—é –ø–µ—Ä–∏–æ–¥: –æ–ø—Ä–µ–¥–µ–ª—è—é –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –∏ –≤—ã–∑—ã–≤–∞—é –º–µ—Ç–æ–¥ get_or_create_period_cached ===
                year = int(row["TIME_PERIOD"])
                period_type = PeriodTypeEnum.YEARLY
                unique_key_period = f"{metric_id}_{series_id}_{year}"

                period = await get_or_create_period_cached(
                    cache=period_cache,
                    unique_key=unique_key_period,
                    session=session,
                    series_id=series_id,
                    period_type=period_type,
                    year=year,
                )
                period_id = cast(int, period.id)

                # === –°–æ–∑–¥–∞—é –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ ===
                try:
                    value = float(row["OBS_VALUE"].strip()) if row["OBS_VALUE"].strip() else None
                except ValueError:
                    logger.warning(f"‚ö†Ô∏è –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ obs_value: {row['obs_value']}")
                    continue

                if value is None:
                    continue

                buffer.append(
                    MetricDataModel(
                        series_id=series_id,
                        period_id=period_id,
                        country_id=country_id,
                        value_float=value,
                        add_info=None,
                    )
                )

                # === –ú–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ ===
                if len(buffer) >= batch_size:
                    session.add_all(buffer)
                    await session.commit()
                    total_inserted += len(buffer)
                    logger.info(f"üíæ –ú–∞—Å—Å–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ ‚Äî {total_inserted} –∑–∞–ø–∏—Å–µ–π")
                    buffer.clear()

    # –§–∏–Ω–∞–ª—å–Ω—ã–π commit –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∑–∞–ø–∏—Å–µ–π
    if buffer:
        session.add_all(buffer)
        await session.commit()
        total_inserted += len(buffer)
        logger.info(f"üíæ –§–∏–Ω–∞–ª—å–Ω—ã–π commit ‚Äî {total_inserted} –∑–∞–ø–∏—Å–µ–π")

    logger.info(f"\n‚úÖ –ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω. –í—Å–µ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_inserted} –∑–∞–ø–∏—Å–µ–π.")


# ================= Main =================
async def main(file_path: Path, mode: Literal["check", "import"]):

    async with AsyncSessionLocal() as session:
        if mode == "check":
            df = pd.read_csv(file_path)
            values = df["REF_AREA"].tolist()
            await compare_country_list_by_column(
                session=session,
                list_string=values,
                column_name="iso_alpha_3",
            )
            return

        elif mode == "import":
            await import_csv(session=session, file_path=file_path)
            return


if __name__ == "__main__":
    raise RuntimeError("–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –Ω–µ–ª—å–∑—è –∑–∞–ø—É—Å–∫–∞—Ç—å –±–µ–∑ –ø—Ä–∏—á–∏–Ω!")

    path = Path("data/OECD.ELS.IMD,DSD_MIG@DF_MIG_NUP_SEX,1.0+..A.EMP_WAP.....csv")
    asyncio.run(main(file_path=path, mode="import"))
