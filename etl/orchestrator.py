# etl/orchestrator.py
"""
–ì–ª–∞–≤–Ω—ã–π –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä ETL
"""
import asyncio
import time
from datetime import datetime
from pathlib import Path
from typing import List, Literal, cast

from sqlalchemy.ext.asyncio import AsyncSession

from etl.config.config_schema import ETLConfig
from etl.services import (
    CacheService,
    DataAssembler,
    DataParser,
    DBService,
    EntityResolver,
    FileReaderService,
    RawRecord,
)
from etl.utils.stats import StatisticsETL
from src.core.config.logging import setup_logger_to_file


logger = setup_logger_to_file()


class ETLOrchestrator:
    """ETL –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä"""

    def __init__(self, config: ETLConfig, session: AsyncSession):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""

        self.config = config
        self.session = session

        # –°–µ—Ä–≤–∏—Å—ã
        self.cache_service = CacheService(config)
        self.db_service = DBService(session)
        self.file_reader = FileReaderService(config)
        self.parser = DataParser(config)
        self.assembler = DataAssembler(config)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.statistics = StatisticsETL()

        self._stop_event = asyncio.Event()
        self._metric_id = None
        self._metric = None

    async def run(self, mode: Literal["check", "load"]):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥, –∑–∞–ø—É—Å–∫–∞—é—â–∏–π ETL"""

        try:
            await self._initialize(mode)

            if mode == "check":
                await self.check_config()
            else:
                await self.import_data()

        finally:
            self.statistics.end_time = datetime.now()
            await self._log_statistics()

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ ETL"""

        self._stop_event.set()
        logger.info("üõë –ó–∞–ø—Ä–æ—à–µ–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ ETL...")

    async def _initialize(self, mode: Literal["check", "load"]):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Å–Ω–æ–≤–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π"""

        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ETL...")
        await self.cache_service.clear_all()

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ
        self.statistics.total_rows = await self.file_reader.get_total_rows()
        logger.info(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫ –≤ —Ñ–∞–π–ª–µ: {self.statistics.total_rows:,}")

        # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω—ã –≤ –∫—ç—à
        await self.cache_service.preload_countries(self.session, self.config.country_column)

        # TODO: –≤–æ—Ç —Ç—É—Ç –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å —É—Å–ª–æ–≤–∏–µ –¥–ª—è –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ –≥–æ—Ä–æ–¥–æ–≤

        if mode == "load":
            # –ü–æ–ª—É—á–∞–µ–º/—Å–æ–∑–¥–∞—ë–º –º–µ—Ç—Ä–∏–∫—É –ø–æ slug
            self._metric = await self.db_service.get_or_create_metric(self.config.metric)
            self._metric_id = cast(int, self._metric.id)
            await self.cache_service.set_metric(cast(str, self._metric.slug), self._metric)

            # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ–º –≤ –∫—ç—à —Å–µ—Ä–∏–∏, –ø–µ—Ä–∏–æ–¥—ã, —Ç–∏–ø—ã –∏ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            await self.cache_service.preload_series(self.session, self._metric_id)
            await self.cache_service.preload_periods(self.session)
            await self.cache_service.preload_attribute_types(self.session)
            await self.cache_service.preload_attribute_values(self.session)

    #
    #
    # ================= –†–µ–∂–∏–º –ø—Ä–æ–≤–µ—Ä–∫–∏ =================
    async def check_config(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å—Ç—Ä–∞–Ω –∏–∑ CSV –≤ –ë–î —Å —É—á—ë—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞."""

        logger.info(f"{'='*20} –†–ï–ñ–ò–ú –ü–†–û–í–ï–†–ö–ò –ö–û–ù–§–ò–ì–ê")

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞
        logger.info("üìñ –ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω –∏–∑ CSV...")
        start_time = time.time()
        countries_in_csv = await self.file_reader.get_unique_countries(
            self.config.metric.country_column, self.config.chank_size
        )

        elapsed = time.time() - start_time
        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(countries_in_csv)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω –∑–∞ {elapsed:.2f} —Å–µ–∫")

        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—Ç—Ä–∞–Ω—ã –∏–∑ –∫—ç—à–∞
        db_countries = await self.cache_service.get_all_countries()
        logger.debug(f"üìä –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω –≤ –ë–î: {len(db_countries)}")

        # –ê–Ω–∞–ª–∏–∑
        countries_found = []  # –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω
        countries_not_found = []  # –°–ø–∏—Å–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞–Ω
        mapping_used = []  # –í–∑—è—Ç–æ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å—Ç—Ä–∞–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ —Å–æ —Å—Ç—Ä–∞–Ω–∞–º–∏ –∏–∑ –ë–î
        for csv_country in sorted(countries_in_csv):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: —Å—Ç—Ä–∞–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞ -> —Å—Ç—Ä–∞–Ω–∞ –∏–∑ –ë–î
            if csv_country in db_countries:
                countries_found.append(csv_country)
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –º–∞–ø–ø–∏–Ω–≥—É: —Å—Ç—Ä–∞–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞ (–º–∞–ø–ø–∏–Ω–≥) -> —Å—Ç—Ä–∞–Ω–∞ –∏–∑ –ë–î
            if csv_country in self.config.country_mapping:
                mapped_names = self.config.country_mapping[csv_country]
                mapped_found = False
                for mapped_name in mapped_names:
                    if mapped_name in db_countries:
                        countries_found.append(csv_country)
                        mapping_used.append(f"'{csv_country}' -> '{mapped_name}'")
                        mapped_found = True
                        break

                    if mapped_found:
                        break

                if not mapped_found:
                    countries_not_found.append(csv_country)

            else:
                countries_not_found.append(csv_country)

        # –°—Ç—Ä–∞–Ω—ã –≤ –ë–î, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ CSV (—Å —É—á—ë—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞)
        reverse_mapping = {}
        for csv_name, db_names in self.config.country_mapping.items():
            for db_name in db_names:
                reverse_mapping.setdefault(db_name, []).append(csv_name)

        # –ü–æ–ª—É—á–∞—é —Å—Ç—Ä–∞–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –ë–î, –Ω–æ –Ω–µ—Ç –≤ —Ñ–∞–π–ª–µ (–¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏)
        countries_in_db_not_in_csv = []
        for db_name, db_id in db_countries.items():
            used = False

            if db_name in countries_in_csv:
                used = True

            if not used:
                lower_db = db_name.lower()
                for csv_country in countries_in_csv:
                    if csv_country.lower() == lower_db:
                        used = True
                        break

            if not used and db_name in reverse_mapping:
                for csv_name in reverse_mapping[db_name]:
                    if csv_name in countries_in_csv:
                        used = True
                        break

            if not used:
                lower_db = db_name.lower()
                for mapped_db_name, csv_names in reverse_mapping.items():
                    if mapped_db_name.lower() == lower_db:
                        for csv_name in csv_names:
                            if csv_name in countries_in_csv:
                                used = True
                                break
                    if used:
                        break

            if not used:
                countries_in_db_not_in_csv.append((db_name, db_id))

        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        logger.info(f"{'='*20} üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        logger.info(f"   –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω –≤ CSV: {len(countries_in_csv)}")
        logger.info(f"   –ù–∞–π–¥–µ–Ω–æ –≤ –ë–î: {len(countries_found)}")
        logger.info(f"   –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ë–î: {len(countries_not_found)}")

        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –º–∞–ø–ø–∏–Ω–≥
        if mapping_used:
            logger.info(f"\nüîÑ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è {len(mapping_used)} —Å—Ç—Ä–∞–Ω:")
            for mapping in mapping_used[:5]:
                logger.info(f"   {mapping}")
            if len(mapping_used) > 5:
                logger.info(f"   ... –∏ –µ—â–µ {len(mapping_used) - 5} –º–∞–ø–ø–∏–Ω–≥–æ–≤")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–æ–≤
        await self._save_country_reports(countries_not_found, countries_in_db_not_in_csv)

    #
    #
    # ================= –ò–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö =================
    async def import_data(self):
        """–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤ –ë–î —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É"""

        logger.info(f"{'='*20} –ò–ú–ü–û–†–¢ –î–ê–ù–ù–´–•")

        raw_buffer: List[RawRecord] = []

        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª —á–∞–Ω–∫–∞–º–∏
        async for chunk_df in self.file_reader.read_chunks(self.config.chank_size):

            # –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
            if self._stop_event.is_set():
                break

            # –ü–∞—Ä—Å–∏–Ω–≥ —á–∞–Ω–∫–∞ ‚Äì –∑–∞–ø—É—Å–∫–∞–µ–º –≤ executor, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop
            loop = asyncio.get_event_loop()
            parsed = await loop.run_in_executor(None, self.parser.parse_chunk, chunk_df)
            raw_buffer.extend(parsed)
            self.statistics.parsed_rows += len(parsed)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∏ (—Å–æ–∑–¥–∞—ë–º –∏/–∏–ª–∏ –ø–æ–ª—É—á–∞–µ–º ID –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ –ë–î –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –ë–î )
            while len(raw_buffer) >= self.config.batch_size and not self._stop_event.is_set():
                batch = raw_buffer[: self.config.batch_size]
                raw_buffer = raw_buffer[self.config.batch_size :]
                await self._process_batch(batch)

        # –û—Å—Ç–∞—Ç–æ–∫
        if raw_buffer and not self._stop_event.is_set():
            await self._process_batch(raw_buffer)

    async def _process_batch(self, batch: List[RawRecord]):
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω –±–∞—Ç—á: —Ä–∞–∑—Ä–µ—à–∏—Ç—å —Å—É—â–Ω–æ—Å—Ç–∏, —Å–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –≤—Å—Ç–∞–≤–∏—Ç—å –≤ –ë–î."""

        logger.info(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∏–∑ {len(batch)} –∑–∞–ø–∏—Å–µ–π...")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–µ—Ä–≤–∏—Å –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á (–ø–æ–ª—É—á–∞–µ–º ID –≤—Å–µ—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ –±–∞—Ç—á–∞)
        resolver = EntityResolver(self.config, self.cache_service, self.db_service, cast(int, self._metric_id))
        country_map, series_map, period_map = await resolver.resolve_batch(batch)

        # –û—Å—É—â–µ—Å—Ç–≤–ª—è–µ–º —Å–±–æ—Ä–∫—É –º–æ–¥–µ–ª–µ–π
        records = self.assembler.assemble(batch, country_map, series_map, period_map)
        self.statistics.resolved_rows += len(records)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –ë–î –¥–∞–Ω–Ω—ã–µ
        if records:
            inserted = await self.db_service.bulk_insert_metric_data(records)
            self.statistics.inserted_rows += inserted

        self.statistics.batches_processed += 1

        if self.statistics.batches_processed % 10 == 0:
            logger.info(
                f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {self.statistics.batches_processed}, "
                f"–≤—Å—Ç–∞–≤–ª–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {self.statistics.inserted_rows:,}"
            )

    #
    #
    # ================= –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –æ—Ç—á—ë—Ç—ã =================
    async def _log_statistics(self):
        """–õ–æ–≥–≥–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∫—É ETL"""

        logger.info(f"{'='*20} üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê ETL")

        logger.info(f"–û–±—â–µ–µ –≤—Ä–µ–º—è: {self.statistics.total_seconds:.2f} —Å–µ–∫")
        logger.info(f"–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {self.statistics.total_rows:,}")
        logger.info(f"–†–∞—Å–ø–∞—Ä—Å–µ–Ω–æ —Å—Ç—Ä–æ–∫: {self.statistics.parsed_rows:,}")
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ (–≤—Å—Ç–∞–≤–ª–µ–Ω–æ): {self.statistics.inserted_rows:,}")
        logger.info(f"–ë–∞—Ç—á–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.statistics.batches_processed}")

        if self.statistics.total_seconds > 0 and self.statistics.parsed_rows > 0:
            rows_per_second = self.statistics.parsed_rows / self.statistics.total_seconds
            logger.info(f"–°–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏: {rows_per_second:.1f} —Å—Ç—Ä–æ–∫/—Å–µ–∫")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–µ–π
        cache_stats = self.cache_service.get_cache_stats()
        logger.info("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–≠–®–ï–ô:")
        for name, stats in cache_stats.items():
            hit_rate = stats.get("hit_rate", 0)
            size = stats.get("size", 0)
            maxsize = stats.get("maxsize", 1)
            fullness = (size / maxsize * 100) if maxsize > 0 else 0
            logger.info(
                f"{stats.get('name', name):25} | Hit rate: {hit_rate:5.1f}% | "
                f"–†–∞–∑–º–µ—Ä: {size:6}/{maxsize:6} ({fullness:5.1f}%) | –í—ã—Ç–µ—Å–Ω–µ–Ω–æ: {stats.get('evictions', 0):6}"
            )
        logger.info("=" * 60)

    async def _save_country_reports(self, countries_not_found: list, countries_in_db_not_in_csv: list) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á—ë—Ç –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã logs/missing_countries.txt –∏ logs/unused_countries.txt"""

        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)

        # –û–°–ù–û–í–ù–û–ï: –æ—Ç—á—ë—Ç –ø–æ —Å—Ç—Ä–∞–Ω–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ —Ñ–∞–π–ª–µ, –Ω–æ –Ω–µ—Ç –≤ –ë–î (—Å —É—á—ë—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞)
        if countries_not_found:
            missing_file = logs_dir / "missing_countries.txt"
            with open(missing_file, "w", encoding="utf-8") as f:
                f.write("# –°—Ç—Ä–∞–Ω—ã –∏–∑ CSV, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ –ë–î\n")
                f.write("# –î–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ country_mapping –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏\n\n")
                for country in sorted(countries_not_found):
                    if country in self.config.country_mapping:
                        mapping = self.config.country_mapping[country]
                        f.write(f"# –ú–∞–ø–ø–∏–Ω–≥ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {country} -> {mapping}\n")
                        f.write(f"# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –º–∞–ø–ø–∏–Ω–≥–∞\n\n")
                    else:
                        f.write(f"# {country}\n")
                        f.write(f"'{country}': [],\n\n")
            logger.info(f"üìù missing_countries.txt —Å–æ–∑–¥–∞–Ω: {missing_file}")

        # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û: –æ—Ç—á—ë—Ç –ø–æ —Å—Ç—Ä–∞–Ω–∞–º, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –ë–î, –Ω–æ –Ω–µ—Ç –≤ —Ñ–∞–π–ª–µ
        if countries_in_db_not_in_csv:
            unused_file = logs_dir / "unused_countries.txt"
            with open(unused_file, "w", encoding="utf-8") as f:
                f.write("# –°—Ç—Ä–∞–Ω—ã –≤ –ë–î, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ CSV\n")
                f.write("# –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ - –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –¥–µ–π—Å—Ç–≤–∏–π\n\n")
                for db_name, db_id in sorted(countries_in_db_not_in_csv, key=lambda x: x[0]):
                    f.write(f"# {db_name} (ID: {db_id})\n")
            logger.info(f"üìù unused_countries.txt —Å–æ–∑–¥–∞–Ω: {unused_file}")

        if countries_not_found:
            logger.info(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {len(countries_not_found)} —Å—Ç—Ä–∞–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ë–î")
            logger.info("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª missing_countries.txt –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞")
            logger.info("   –ò–º–ø–æ—Ä—Ç –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–∏—Ö —Å—Ç—Ä–∞–Ω")
        else:
            logger.info(f"\n‚úÖ –û—Ç–ª–∏—á–Ω–æ! –í—Å–µ —Å—Ç—Ä–∞–Ω—ã –∏–∑ CSV –Ω–∞–π–¥–µ–Ω—ã –≤ –ë–î")
