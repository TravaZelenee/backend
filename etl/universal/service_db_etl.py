# etl/universal/service_db_etl.py
"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –≤ ETL
"""
import asyncio
import time
from typing import Any, Dict, List, Optional, Tuple, cast

from sqlalchemy import and_, func, select, text
from sqlalchemy.ext.asyncio import AsyncSession
from tenacity import retry, stop_after_attempt, wait_exponential

from etl.universal.config_schema import (
    AttributeConfig,
    AttributeParsingStrategyEnum,
    AttributeTypeDTO,
    AttributeValueDTO,
    ComplexParseResultDTO,
    ETLConfig,
    FieldSourceDTO,
    FieldSourceTypeEnum,
    MetricConfig,
    ParsedAttributeDTO,
    PeriodConfig,
    PeriodDataDTO,
)
from etl.universal.lru_caches import LRUCache
from src.core.config.logging import setup_logger_to_file
from src.core.enums import TypeDataEnum
from src.ms_location.models import CityModel, CountryModel
from src.ms_metric.models import (
    MetricAttributeTypeModel,
    MetricAttributeValueModel,
    MetricDataNewModel,
    MetricInfoNewModel,
    MetricPeriodNewModel,
    MetricSeriesAttribute,
    MetricSeriesNewModel,
)


logger = setup_logger_to_file()


class DB_ServiceUniversalETL:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö –≤ ETL"""

    def __init__(self, session: AsyncSession, config: ETLConfig):
        self.session = session
        self.config = config

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LRU –∫—ç—à–∏ —Å —Ä–∞–∑—É–º–Ω—ã–º–∏ —Ä–∞–∑–º–µ—Ä–∞–º–∏
        self._country_cache = LRUCache(maxsize=self.config.cache.country_size, name=self.config.cache.country_name)
        self._city_cache = LRUCache(maxsize=self.config.cache.city_size, name=self.config.cache.city_name)
        self._metric_cache = LRUCache(maxsize=self.config.cache.metric_size, name=self.config.cache.metric_name)
        self._series_cache = LRUCache(maxsize=self.config.cache.series_size, name=self.config.cache.series_name)
        self._period_cache = LRUCache(maxsize=self.config.cache.period_size, name=self.config.cache.period_name)

        # –î–ª—è attribute_value_cache –∏—Å–ø–æ–ª—å–∑—É–µ–º Tuple[int, str] –∫–∞–∫ –∫–ª—é—á
        self._attribute_type_cache = LRUCache(
            maxsize=self.config.cache.attribute_type_size, name=self.config.cache.attribute_type_name
        )
        self._attribute_value_cache = LRUCache(
            maxsize=self.config.cache.attribute_value_size, name=self.config.cache.attribute_value_name
        )

        # –§–ª–∞–≥ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω
        self._countries_preloaded = False

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {"duplicates_skipped": 0, "new_records": 0, "cache_stats": {}}

    #
    #
    # ============ –û–ë–©–ò–ï –ú–ï–¢–û–î–´ –¥–ª—è –ö–≠–®–ê ============
    def _get_cache_key_for_attribute_value(self, attr_type_id: int, value_code: str) -> Tuple[int, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –¥–ª—è –∫—ç—à–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""

        return (attr_type_id, value_code)

    async def _clear_caches_after_rollback(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à–∏ –ø–æ—Å–ª–µ –æ—Ç–∫–∞—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"""

        logger.info("–û—á–∏—Å—Ç–∫–∞ –∫—ç—à–µ–π –ø–æ—Å–ª–µ –æ—Ç–∫–∞—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏...")

        # –û—á–∏—â–∞–µ–º –≤—Å–µ –∫—ç—à–∏
        self._attribute_type_cache.clear()
        self._attribute_value_cache.clear()
        self._series_cache.clear()
        self._period_cache.clear()

        logger.info("–ö—ç—à–∏ –æ—á–∏—â–µ–Ω—ã")

    async def clear_all_caches(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Å–µ –∫—ç—à–∏"""
        logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫—ç—à–µ–π...")

        self._country_cache.clear()
        self._city_cache.clear()
        self._metric_cache.clear()
        self._series_cache.clear()
        self._period_cache.clear()
        self._attribute_type_cache.clear()
        self._attribute_value_cache.clear()

        self._countries_preloaded = False
        logger.info("‚úÖ –í—Å–µ –∫—ç—à–∏ –æ—á–∏—â–µ–Ω—ã")

    async def _update_cache_stats(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–µ–π"""

        self.stats["cache_stats"] = {
            "country_cache": self._country_cache.stats(),
            "city_cache": self._city_cache.stats(),
            "metric_cache": self._metric_cache.stats(),
            "series_cache": self._series_cache.stats(),
            "period_cache": self._period_cache.stats(),
            "attribute_type_cache": self._attribute_type_cache.stats(),
            "attribute_value_cache": self._attribute_value_cache.stats(),
        }

    async def log_cache_stats(self):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–µ–π"""

        await self._update_cache_stats()

        logger.debug("\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–≠–®–ï–ô:")
        for _, stats in self.stats["cache_stats"].items():
            logger.debug(f"  {stats['name']}:")
            logger.debug(f"    –†–∞–∑–º–µ—Ä: {stats['size']}/{stats['maxsize']} ({stats['fullness']})")
            logger.debug(f"    –ü–æ–ø–∞–¥–∞–Ω–∏—è: {stats['hits']}, –ü—Ä–æ–º–∞—Ö–∏: {stats['misses']}")
            logger.debug(f"    –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {stats['hit_rate']}")
            if stats["evictions"] > 0:
                logger.debug(f"    –í—ã—Ç–µ—Å–Ω–µ–Ω–æ: {stats['evictions']}")

    #
    #
    # ============ –û–ë–©–ò–ï –ú–ï–¢–û–î–´ ============
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    async def _execute_with_retry(self, stmt):
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å —Å —Ä–µ—Ç—Ä–∞—è–º–∏"""

        try:
            # logger.debug(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL: {stmt}")
            result = await self.session.execute(stmt)
            return result

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ SQL: {e}")

            # –ï—Å–ª–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞, –ø—Ä–æ–±—É–µ–º –æ—Ç–∫–∞—Ç–∏—Ç—å –∏ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å
            if "current transaction is aborted" in str(e) or "InFailedSQLTransactionError" in str(e):
                logger.warning("–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –ø—Ä–µ—Ä–≤–∞–Ω–∞, –ø—ã—Ç–∞–µ–º—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å...")

                try:
                    await self.session.rollback()

                    await self._clear_caches_after_rollback()  # –û–ß–ò–©–ê–ï–ú –ö–≠–® –ü–û–°–õ–ï –û–¢–ö–ê–¢–ê

                    logger.info("–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –æ—Ç–∫–∞—á–µ–Ω–∞, –∫—ç—à –æ—á–∏—â–µ–Ω, –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å...")
                except Exception as rollback_error:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–∫–∞—Ç–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {rollback_error}")

            raise

    async def bulk_insert_metric_data(self, records: List[MetricDataNewModel]) -> int:
        """–ë—ã—Å—Ç—Ä–∞—è –º–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω–¥–µ–∫—Å —Å COALESCE)"""

        logger.debug(f"Bulk insert {len(records)} –∑–∞–ø–∏—Å–µ–π...")

        if not records:
            return 0

        try:
            # 1. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            await self.session.execute(
                text(
                    """
                CREATE TEMP TABLE temp_metric_data (
                    series_id INTEGER,
                    period_id INTEGER,
                    country_id INTEGER,
                    city_id INTEGER,
                    value_numeric NUMERIC,
                    value_string VARCHAR,
                    value_boolean BOOLEAN,
                    value_range_start NUMERIC,
                    value_range_end NUMERIC,
                    meta_data JSONB,
                    created_at TIMESTAMPTZ,
                    updated_at TIMESTAMPTZ
                ) ON COMMIT DROP
            """
                )
            )

            # 2. –í—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            values_list = []
            for record in records:
                values_list.append(
                    {
                        "series_id": record.series_id,
                        "period_id": record.period_id,
                        "country_id": record.country_id,
                        "city_id": record.city_id,
                        "value_numeric": record.value_numeric,
                        "value_string": record.value_string,
                        "value_boolean": record.value_boolean,
                        "value_range_start": record.value_range_start,
                        "value_range_end": record.value_range_end,
                        "meta_data": record.meta_data,
                        "created_at": record.created_at,
                        "updated_at": record.updated_at,
                    }
                )

            # 3. –í—Å—Ç–∞–≤–ª—è–µ–º –±–∞—Ç—á–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
            insert_temp = text(
                """
                INSERT INTO temp_metric_data 
                VALUES (:series_id, :period_id, :country_id, :city_id,
                        :value_numeric, :value_string, :value_boolean,
                        :value_range_start, :value_range_end,
                        :meta_data, :created_at, :updated_at)
            """
            )

            await self.session.execute(insert_temp, values_list)

            # 4. –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã –≤ –æ—Å–Ω–æ–≤–Ω—É—é, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            insert_stmt = text(
                """
                INSERT INTO metric_data_new 
                (series_id, period_id, country_id, city_id,
                value_numeric, value_string, value_boolean,
                value_range_start, value_range_end,
                meta_data, created_at, updated_at)
                SELECT 
                    series_id, period_id, country_id, city_id,
                    value_numeric, value_string, value_boolean,
                    value_range_start, value_range_end,
                    meta_data, created_at, updated_at
                FROM temp_metric_data t
                WHERE NOT EXISTS (
                    SELECT 1 
                    FROM metric_data_new m
                    WHERE m.series_id = t.series_id
                    AND m.country_id = t.country_id
                    AND m.period_id = t.period_id
                    AND COALESCE(m.city_id, -1) = COALESCE(t.city_id, -1)
                )
            """
            )

            result = await self.session.execute(insert_stmt)
            total_inserted = result.rowcount

            await self.session.commit()

            logger.info(f"‚úÖ –í—Å—Ç–∞–≤–ª–µ–Ω–æ {total_inserted} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–∑ {len(records)}")
            self.stats["duplicates_skipped"] = len(records) - total_inserted
            self.stats["new_records"] = total_inserted

            logger.debug(f"Bulk insert {len(records)} –∑–∞–ø–∏—Å–µ–π...")

            return total_inserted

        except Exception as e:
            await self.session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ bulk insert: {e}")
            await self._clear_caches_after_rollback()
            raise

    #
    #
    # ============ –û–ë–†–ê–ë–û–¢–ö–ê –ê–¢–†–ò–ë–£–¢–û–í ============
    async def _parse_attribute(
        self, row: Dict[str, str], attr_config: AttributeConfig
    ) -> Tuple[List[ParsedAttributeDTO], Optional[PeriodDataDTO]]:
        """–ü–∞—Ä—Å–∏—Ç –∞—Ç—Ä–∏–±—É—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""

        value = row.get(attr_config.csv_column)

        if not value:
            return [], None

        # –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–∞—è
        if attr_config.parsing_strategy == AttributeParsingStrategyEnum.FIXED_TYPE:

            assert attr_config.attribute_type_code is not None  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –±—É–¥—É—Ç –∑–∞–¥–∞–Ω—ã
            assert attr_config.attribute_type_name is not None  # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –±—É–¥—É—Ç –∑–∞–¥–∞–Ω—ã

            attribute = ParsedAttributeDTO(
                type=AttributeTypeDTO(
                    code=attr_config.attribute_type_code,
                    name=attr_config.attribute_type_name,
                    value_type=attr_config.def_type_value_type,
                    is_active=attr_config.def_type_is_active,
                    is_filtered=attr_config.def_type_is_filtered,
                    sort_order=attr_config.def_type_sort_order,
                    meta_data=attr_config.def_type_meta_data,
                ),
                value=AttributeValueDTO(
                    code=value,
                    name=value,
                    is_active=attr_config.def_value_is_active,
                    is_filtered=attr_config.def_value_is_filtered,
                    sort_order=attr_config.def_value_sort_order,
                    meta_data=attr_config.def_value_meta_data,
                ),
            )
            return [attribute], None

        # –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–∞—Å—Ç–æ–º–Ω–∞—è
        elif attr_config.parsing_strategy == AttributeParsingStrategyEnum.CUSTOM:

            if not attr_config.custom_parser:
                logger.error("‚ùå –î–ª—è CUSTOM —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–¥–∞–Ω custom_parser")
                raise ValueError("‚ùå –î–ª—è CUSTOM —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–¥–∞–Ω custom_parser")

            result = attr_config.custom_parser(value)

            if isinstance(result, ParsedAttributeDTO):
                return [result], None
            else:
                logger.error(f"‚ùå –ö–∞—Å—Ç–æ–º–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –≤–µ—Ä–Ω—É–ª –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø: {type(result)}")
                return [], None

        # –ï—Å–ª–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–∞—è
        elif attr_config.parsing_strategy == AttributeParsingStrategyEnum.COMPLEX:

            if not attr_config.complex_parser:
                logger.error("‚ùå –î–ª—è COMPLEX —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–¥–∞–Ω complex_parser")
                raise ValueError("‚ùå –î–ª—è COMPLEX —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–¥–∞–Ω complex_parserr")

            result = attr_config.complex_parser(value)

            if isinstance(result, ComplexParseResultDTO):
                return result.attributes, result.period_data
            else:
                logger.error(f"‚ùå Complex parser –≤–µ—Ä–Ω—É–ª –Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø: {type(result)}")
                return [], None

        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞: {row=}, {attr_config.parsing_strategy=}")
        return [], None

    async def get_or_create_attribute_type(self, parsed_attr: ParsedAttributeDTO) -> MetricAttributeTypeModel:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç —Ç–∏–ø –∞—Ç—Ä–∏–±—É—Ç–∞ —Å LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

        type_code = parsed_attr.type.code

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_type = self._attribute_type_cache.get(type_code)
        if cached_type:
            return cached_type

        # –ò—â–µ–º –≤ –ë–î
        stmt = select(MetricAttributeTypeModel).where(MetricAttributeTypeModel.code == type_code)
        result = await self._execute_with_retry(stmt)
        attr_type = result.scalar_one_or_none()

        if not attr_type:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç–∏–ø –∞—Ç—Ä–∏–±—É—Ç–∞
            attr_type = MetricAttributeTypeModel(
                code=parsed_attr.type.code,
                name=parsed_attr.type.name,
                value_type=parsed_attr.type.value_type,
                is_filtered=parsed_attr.type.is_filtered,
                sort_order=parsed_attr.type.sort_order,
                is_active=parsed_attr.type.is_active,
                meta_data=parsed_attr.type.meta_data,
            )
            self.session.add(attr_type)
            await self.session.flush()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self._attribute_type_cache.set(type_code, attr_type)
        return attr_type

    async def get_or_create_attribute_value(
        self, attr_type: MetricAttributeTypeModel, parsed_attr: ParsedAttributeDTO
    ) -> MetricAttributeValueModel:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞ —Å LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

        cache_key = self._get_cache_key_for_attribute_value(cast(int, attr_type.id), parsed_attr.value.code)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_value = self._attribute_value_cache.get(cache_key)
        if cached_value:
            return cached_value

        # –ò—â–µ–º –≤ –ë–î
        stmt = select(MetricAttributeValueModel).where(
            MetricAttributeValueModel.attribute_type_id == attr_type.id,
            MetricAttributeValueModel.code == parsed_attr.value.code,
        )
        result = await self._execute_with_retry(stmt)
        attr_value = result.scalar_one_or_none()

        if not attr_value:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞
            attr_value = MetricAttributeValueModel(
                attribute_type_id=attr_type.id,
                code=parsed_attr.value.code,
                name=parsed_attr.value.name,
                is_active=parsed_attr.value.is_active,
                is_filtered=parsed_attr.value.is_filtered,
                sort_order=parsed_attr.value.sort_order,
                meta_data=parsed_attr.value.meta_data,
            )
            self.session.add(attr_value)
            await self.session.flush()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self._attribute_value_cache.set(cache_key, attr_value)
        return attr_value

    async def process_attributes(
        self, row: Dict[str, str], attributes_config: List[AttributeConfig]
    ) -> Tuple[List[Tuple[MetricAttributeTypeModel, MetricAttributeValueModel]], Optional[PeriodDataDTO]]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã —Å—Ç—Ä–æ–∫–∏"""
        # start = time.time()
        all_attributes = []
        complex_period_data = None

        for attr_config in attributes_config:
            try:

                attributes, period_data = await self._parse_attribute(row, attr_config)

                for parsed_attr in attributes:
                    attr_type = await self.get_or_create_attribute_type(parsed_attr)
                    attr_value = await self.get_or_create_attribute_value(attr_type, parsed_attr)
                    all_attributes.append((attr_type, attr_value))

                if period_data and not complex_period_data:
                    complex_period_data = period_data

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∞—Ç—Ä–∏–±—É—Ç–∞ {attr_config.csv_column}: {e}")
                logger.error(f"   –ó–Ω–∞—á–µ–Ω–∏–µ: {row.get(attr_config.csv_column, '')}")
                logger.error(f"   –°—Ç—Ä–æ–∫–∞: {row}")
                raise

        # logger.debug(f"parse_attributes –¥–ª—è —Å—Ç—Ä–æ–∫–∏: {time.time() - start}")
        return all_attributes, complex_period_data

    #
    #
    # ============ –ì–ï–û–ì–†–ê–§–ò–ß–ï–°–ö–ò–ï –û–ë–™–ï–ö–¢–´ ============
    async def get_country_id(
        self, country_name: str, country_mapping: Dict[str, List[str]], column_name: str
    ) -> Optional[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç ID —Å—Ç—Ä–∞–Ω—ã —Å —É—á–µ—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞, LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏"""

        # logger.debug(f"–ü–æ–∏—Å–∫ —Å—Ç—Ä–∞–Ω—ã: {country_name}")
        if not country_name:
            return None

        original_name = country_name.strip()

        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (–±—ã—Å—Ç—Ä–µ–µ –≤—Å–µ–≥–æ)
        cached_id = self._country_cache.get(original_name)
        if cached_id is not None:
            return cached_id

        # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥ (–∫–ª—é—á - –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ CSV)
        if original_name in country_mapping:
            db_names = country_mapping[original_name]

            # –ü—Ä–æ–±—É–µ–º –∫–∞–∂–¥–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ —Å–ø–∏—Å–∫–∞
            for db_name in db_names:
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à –¥–ª—è db_name
                cached_id = self._country_cache.get(db_name)
                if cached_id is not None:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
                    self._country_cache.set(original_name, cached_id)
                    logger.debug(f"–ú–∞–ø–ø–∏–Ω–≥ –∏–∑ –∫—ç—à–∞: '{original_name}' ‚Üí '{db_name}' ‚Üí ID: {cached_id}")
                    return cached_id

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º lowercase –≤–µ—Ä—Å–∏—é db_name
                lower_db_name = db_name.lower()
                cached_id = self._country_cache.get(lower_db_name)
                if cached_id is not None:
                    self._country_cache.set(original_name, cached_id)
                    self._country_cache.set(db_name, cached_id)
                    logger.debug(f"–ú–∞–ø–ø–∏–Ω–≥ –∏–∑ –∫—ç—à–∞ (lowercase): '{original_name}' ‚Üí '{db_name}' ‚Üí ID: {cached_id}")
                    return cached_id

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –∫—ç—à–µ, –∏—â–µ–º –≤ –ë–î –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ db_name
            if db_names and hasattr(CountryModel, column_name):
                db_name = db_names[0]
                column = getattr(CountryModel, column_name)
                stmt = select(CountryModel).where(column == db_name)
                result = await self._execute_with_retry(stmt)
                country = result.scalar_one_or_none()

                if country:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –¥–ª—è –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
                    self._country_cache.set(original_name, country.id)
                    self._country_cache.set(db_name, country.id)
                    self._country_cache.set(db_name.lower(), country.id)

                    logger.debug(f"–ú–∞–ø–ø–∏–Ω–≥ –∏–∑ –ë–î: '{original_name}' ‚Üí '{db_name}' ‚Üí ID: {country.id}")
                    return country.id

            logger.warning(f"–î–ª—è —Å—Ç—Ä–∞–Ω—ã '{original_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤ –ë–î –∏–∑ —Å–ø–∏—Å–∫–∞: {db_names}")
            return None

        # 4. –ï—Å–ª–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–µ—Ç –∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –∫—ç—à–µ, –∏—â–µ–º –≤ –ë–î
        if hasattr(CountryModel, column_name):
            column = getattr(CountryModel, column_name)
            stmt = select(CountryModel).where(column == original_name)
            result = await self._execute_with_retry(stmt)
            country = result.scalar_one_or_none()

            if country:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                self._country_cache.set(original_name, country.id)
                return country.id

        logger.debug(f"–°—Ç—Ä–∞–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∏ –≤ –∫—ç—à–µ, –Ω–∏ –≤ –ë–î: '{original_name}'")
        return None

    async def get_city_id(self, city_name: str, country_id: int, city_mapping: Dict[str, List[str]]) -> Optional[int]:
        """–ü–æ–ª—É—á–∞–µ—Ç ID –≥–æ—Ä–æ–¥–∞ —Å —É—á–µ—Ç–æ–º –º–∞–ø–ø–∏–Ω–≥–∞"""

        if not city_name or not country_id:
            return None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∞–ø–ø–∏–Ω–≥
        for mapped_name, variations in city_mapping.items():
            if city_name in variations:
                city_name = mapped_name
                break

        # –ü–æ–∏—Å–∫ –≥–æ—Ä–æ–¥–∞ –≤ –∫—ç—à–µ
        cached_city_id = self._city_cache.get(f"{country_id}_{city_name}")
        if cached_city_id is not None:
            return cached_city_id

        # –ò—â–µ–º –≤ –ë–î
        stmt = select(CityModel).where(and_(CityModel.country_id == country_id, CityModel.name_eng == city_name))
        result = await self._execute_with_retry(stmt)
        city = result.scalar_one_or_none()

        if city:
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—ç—à
            self._city_cache.set(f"{country_id}_{city_name}", cast(int, city.id))
            return cast(int, city.id)

        logger.warning(f"–ì–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω: {city_name} –¥–ª—è —Å—Ç—Ä–∞–Ω—ã ID: {country_id}")
        return None

    async def _get_all_countries_from_db(self) -> Dict[str, int]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω—ã –∏–∑ –ë–î –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è {name_eng: id}"""

        try:

            stmt = select(CountryModel.name_eng, CountryModel.id)
            result = await self.session.execute(stmt)
            countries = result.all()

            return {name_eng: country_id for name_eng, country_id in countries}

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–∞–Ω –∏–∑ –ë–î: {e}")
            return {}

    #
    #
    # ============ –ú–ï–¢–†–ò–ö–ò –ò –°–ï–†–ò–ò ============
    async def get_or_create_metric(self, metric_config: MetricConfig) -> MetricInfoNewModel:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –º–µ—Ç—Ä–∏–∫—É"""

        logger.debug(f"–ü–æ–∏—Å–∫ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ slug: '{metric_config.slug}'")

        # –ü–æ–∏—Å–∫ –º–µ—Ç—Ä–∏–∫–∏ –≤ –∫—ç—à–µ
        cached_metric = self._metric_cache.get(metric_config.slug)
        if cached_metric:
            logger.debug(f"–ú–µ—Ç—Ä–∏–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ –∫—ç—à–µ: {metric_config.slug}")
            return cached_metric

        stmt = select(MetricInfoNewModel).where(MetricInfoNewModel.slug == metric_config.slug)
        logger.debug(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏: {metric_config.slug}")

        try:
            result = await self._execute_with_retry(stmt)
            metric = result.scalar_one_or_none()

            if not metric:
                logger.info(f"–ú–µ—Ç—Ä–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é: {metric_config.name}")
                metric = MetricInfoNewModel(
                    slug=metric_config.slug,
                    name=metric_config.name,
                    description=metric_config.description,
                    category=metric_config.category,
                    data_type=metric_config.data_type.value,
                    source_name=metric_config.source_name,
                    source_url=metric_config.source_url,
                    show_in_country_list=metric_config.show_in_country_list,
                    show_in_country_detail=metric_config.show_in_country_detail,
                    show_in_city_list=metric_config.show_in_city_list,
                    show_in_city_detail=metric_config.show_in_city_detail,
                    list_priority=metric_config.list_priority,
                    detail_priority=metric_config.detail_priority,
                    is_primary=metric_config.is_primary,
                    is_secondary=metric_config.is_secondary,
                    meta_data=metric_config.meta_data,
                    is_active=metric_config.is_active,
                )
                self.session.add(metric)

                try:
                    await self.session.flush()
                    logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∞ —Å–æ–∑–¥–∞–Ω–∞: {metric_config.name} (ID: {metric.id})")

                except Exception as flush_error:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫–∏: {flush_error}")
                    logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(flush_error).__name__}")
                    await self.session.rollback()
                    raise
            else:
                logger.info(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∞ –Ω–∞–π–¥–µ–Ω–∞ –≤ –ë–î: {metric.name} (ID: {metric.id})")

            self._metric_cache.set(metric_config.slug, metric)
            return metric

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ get_or_create_metric: {e}")
            logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            raise

    async def get_or_create_series(
        self,
        metric_id: int,
        attributes: List[Tuple[MetricAttributeTypeModel, MetricAttributeValueModel]],
        series_metadata: Optional[Dict[str, Any]] = None,
    ) -> MetricSeriesNewModel:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç —Å–µ—Ä–∏—é —Å LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

        start = time.time()

        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞
        attr_parts = []
        for attr_type, attr_value in sorted(attributes, key=lambda x: (x[0].code, x[1].code)):
            attr_parts.append(f"{attr_type.id}:{attr_value.id}")

        cache_key = f"series_{metric_id}_{'_'.join(attr_parts)}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_series = self._series_cache.get(cache_key)
        if cached_series:
            return cached_series

        # 1. –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–µ—Ä–∏—é –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
        existing_series = await self._find_series_by_attributes(metric_id, attributes)

        if existing_series:
            self._series_cache.set(cache_key, existing_series)
            return existing_series

        # 2. –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é —Å–µ—Ä–∏—é
        series = MetricSeriesNewModel(metric_id=metric_id, is_active=True, is_preset=False, meta_data=series_metadata)
        self.session.add(series)
        await self.session.flush()

        # 3. –°–æ–∑–¥–∞–µ–º —Å–≤—è–∑–∏ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏
        for attr_type, attr_value in attributes:
            series_attr = MetricSeriesAttribute(
                series_id=series.id,
                attribute_type_id=attr_type.id,
                attribute_value_id=attr_value.id,
                is_primary=True,
                is_filtered=None,
                sort_order=0,
            )
            self.session.add(series_attr)

        await self.session.flush()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        self._series_cache.set(cache_key, series)
        # logger.debug(f"get_or_create_series: {time.time() - start}")

        return series

    async def _find_series_by_attributes(
        self, metric_id: int, attributes: List[Tuple[MetricAttributeTypeModel, MetricAttributeValueModel]]
    ) -> Optional[MetricSeriesNewModel]:
        """–ù–∞—Ö–æ–¥–∏—Ç —Å–µ—Ä–∏—é –ø–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""

        if not attributes:
            return None

        # –î–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å–æ–∑–¥–∞–µ–º —É—Å–ª–æ–≤–∏–µ
        attribute_conditions = []
        for attr_type, attr_value in attributes:
            subquery = (
                select(MetricSeriesAttribute.series_id)
                .where(
                    MetricSeriesAttribute.attribute_type_id == attr_type.id,
                    MetricSeriesAttribute.attribute_value_id == attr_value.id,
                )
                .scalar_subquery()
            )
            attribute_conditions.append(subquery)

        # –ò—â–µ–º —Å–µ—Ä–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç –í–°–ï —É–∫–∞–∑–∞–Ω–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        # –∏ –∏–º–µ—é—Ç —Ä–æ–≤–Ω–æ —Å—Ç–æ–ª—å–∫–æ –∞—Ç—Ä–∏–±—É—Ç–æ–≤, —Å–∫–æ–ª—å–∫–æ —É–∫–∞–∑–∞–Ω–æ
        series_stmt = (
            select(MetricSeriesNewModel)
            .join(MetricSeriesAttribute, MetricSeriesNewModel.id == MetricSeriesAttribute.series_id)
            .where(
                MetricSeriesNewModel.metric_id == metric_id,
                *[MetricSeriesNewModel.id.in_(condition) for condition in attribute_conditions],
            )
            .group_by(MetricSeriesNewModel.id)
            .having(func.count(MetricSeriesAttribute.id) == len(attributes))
        )

        result = await self._execute_with_retry(series_stmt)
        return result.scalar_one_or_none()

    #
    #
    # ============ –ü–ï–†–ò–û–î–´============
    async def get_or_create_period(
        self,
        series_id: int,
        period_config: PeriodConfig,
        row: Dict[str, str],
        complex_period_data: Optional[PeriodDataDTO] = None,
    ) -> MetricPeriodNewModel:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ —Å LRU –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥–∞
        period_dto = await self._collect_period_data(period_config, row, complex_period_data)

        # –ö–ª—é—á –¥–ª—è –∫—ç—à–∞ –ø–µ—Ä–∏–æ–¥–æ–≤
        cache_key = f"{series_id}_{period_config.period_type}_{period_dto.period_year}"
        if period_dto.period_month:
            cache_key += f"_{period_dto.period_month}"
        if period_dto.period_quarter:
            cache_key += f"_q{period_dto.period_quarter}"
        if period_dto.period_week:
            cache_key += f"_w{period_dto.period_week}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_period = self._period_cache.get(cache_key)
        if cached_period:
            return cached_period

        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –ø–µ—Ä–∏–æ–¥ –≤ –ë–î
        stmt = select(MetricPeriodNewModel).where(
            and_(
                MetricPeriodNewModel.series_id == series_id,
                MetricPeriodNewModel.period_type == period_config.period_type.value,
                MetricPeriodNewModel.period_year == period_dto.period_year,
                MetricPeriodNewModel.period_month == period_dto.period_month,
                MetricPeriodNewModel.period_quarter == period_dto.period_quarter,
                MetricPeriodNewModel.period_week == period_dto.period_week,
            )
        )
        result = await self._execute_with_retry(stmt)
        period = result.scalar_one_or_none()

        if not period:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø–µ—Ä–∏–æ–¥
            period = MetricPeriodNewModel(
                series_id=series_id,
                period_type=period_config.period_type.value,
                period_year=period_dto.period_year,
                period_month=period_dto.period_month,
                period_quarter=period_dto.period_quarter,
                period_week=period_dto.period_week,
                date_start=period_dto.date_start,
                date_end=period_dto.date_end,
                collected_at=period_dto.collected_at,
                meta_data=period_dto.meta_data,
                is_active=True,
            )
            self.session.add(period)
            await self.session.flush()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –ø–µ—Ä–∏–æ–¥–æ–≤
        self._period_cache.set(cache_key, period)
        return period

    async def _collect_period_data(
        self, period_config: PeriodConfig, row: Dict[str, str], complex_period_data: Optional[PeriodDataDTO] = None
    ) -> PeriodDataDTO:
        """–°–æ–±–∏—Ä–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥–∞ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª–æ–≤–∞—Ä—å
        period_dict: Dict[str, Any] = {}

        # –°–Ω–∞—á–∞–ª–∞ –±–µ—Ä–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ complex_parser (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω DTO)
        if complex_period_data:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DTO –≤ —Å–ª–æ–≤–∞—Ä—å (–±–µ–∑ None –∑–Ω–∞—á–µ–Ω–∏–π)
            period_dict.update(complex_period_data.model_dump(exclude_none=True))

        # –ó–∞—Ç–µ–º –∑–∞–ø–æ–ª–Ω—è–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–æ)
        fields_mapping: dict[str, Optional[FieldSourceDTO]] = {
            "period_year": period_config.period_year,
            "period_month": period_config.period_month,
            "period_quarter": period_config.period_quarter,
            "period_week": period_config.period_week,
            "date_start": period_config.date_start,
            "date_end": period_config.date_end,
            "collected_at": period_config.collected_at,
        }

        for field_name, field_source in fields_mapping.items():
            if field_source and field_name not in period_dict:
                value = await self._get_field_value(field_source, row)
                if value is not None:
                    period_dict[field_name] = value

        # –°–æ–∑–¥–∞–µ–º DTO
        try:
            period_dto = PeriodDataDTO(
                period_year=period_dict.get("period_year"),
                period_month=period_dict.get("period_month"),
                period_quarter=period_dict.get("period_quarter"),
                period_week=period_dict.get("period_week"),
                date_start=period_dict.get("date_start"),
                date_end=period_dict.get("date_end"),
                collected_at=period_dict.get("collected_at"),
                meta_data=period_dict.get("meta_data"),
            )
            return period_dto

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PeriodDataDTO: {e}")
            logger.error(f"–î–∞–Ω–Ω—ã–µ: {period_dict}")
            raise

    async def _get_field_value(self, field_source: FieldSourceDTO, row: Dict[str, str]) -> Any:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""

        if field_source.source_type == FieldSourceTypeEnum.COLUMN:
            value = row.get(field_source.column_name or "", "").strip()
            if field_source.transform_callback:
                value = field_source.transform_callback(value)
            return value if value else None

        elif field_source.source_type == FieldSourceTypeEnum.FIXED:
            return field_source.fixed_value

        elif field_source.source_type == FieldSourceTypeEnum.CALLBACK and field_source.callback:
            return field_source.callback(row)

        return None

    #
    #
    # ============ –î–ê–ù–ù–´–ï –ú–ï–¢–†–ò–ö============
    async def create_metric_data(
        self,
        series_id: int,
        period_id: int,
        country_id: int,
        city_id: Optional[int],
        value: str,
        data_type: TypeDataEnum,
    ) -> Optional[MetricDataNewModel]:
        """–°–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
        value_numeric = None
        value_string = None
        value_boolean = None
        value_range_start = None
        value_range_end = None

        try:
            if data_type == TypeDataEnum.FLOAT:
                value_numeric = float(value.replace(",", ".")) if value else None
            elif data_type == TypeDataEnum.STRING:
                value_string = str(value) if value else None
            elif data_type == TypeDataEnum.BOOL:
                value_boolean = value.lower() in ["true", "yes", "1", "–¥–∞"] if value else None
            elif data_type == TypeDataEnum.RANGE:
                if value and "-" in value:
                    parts = value.split("-")
                    if len(parts) == 2:
                        value_range_start = float(parts[0].replace(",", ".")) if parts[0] else None
                        value_range_end = float(parts[1].replace(",", ".")) if parts[1] else None
        except (ValueError, AttributeError) as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ '{value}': {e}")
            return None

        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç (–Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–µ—Å—Å–∏—é!)
        data_record = MetricDataNewModel(
            series_id=series_id,
            period_id=period_id,
            country_id=country_id,
            city_id=city_id,
            value_numeric=value_numeric,
            value_string=value_string,
            value_boolean=value_boolean,
            value_range_start=value_range_start,
            value_range_end=value_range_end,
        )

        return data_record

    #
    #
    # ============ –ü–†–ï–î–ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ============
    async def preload_countries(self, column_name: str):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω—ã –∏–∑ –ë–î –≤ –∫—ç—à"""

        if self._countries_preloaded:
            logger.debug("–°—Ç—Ä–∞–Ω—ã —É–∂–µ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            return

        logger.debug(f"üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω –∏–∑ –ë–î (–∫–æ–ª–æ–Ω–∫–∞: {column_name})...")
        start_time = asyncio.get_event_loop().time()

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –∫–æ–ª–æ–Ω–∫–∞
            if not hasattr(CountryModel, column_name):
                logger.error(f"‚ùå –ö–æ–ª–æ–Ω–∫–∞ '{column_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ CountryModel")
                return

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç—Ä–∞–Ω—ã
            column = getattr(CountryModel, column_name)
            stmt = select(CountryModel.id, column)
            result = await self._execute_with_retry(stmt)
            countries = result.all()

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –∫—ç—à
            count = 0
            for country_id, country_name in countries:
                if country_name:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –ø—É—Å—Ç–æ–µ
                    self._country_cache.set(country_name, country_id)
                    count += 1

            # –¢–∞–∫–∂–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ lowercase –¥–ª—è case-insensitive –ø–æ–∏—Å–∫–∞
            for country_id, country_name in countries:
                if country_name:
                    lower_name = country_name.lower()
                    self._country_cache.set(lower_name, country_id)
                    count += 1

            elapsed = asyncio.get_event_loop().time() - start_time
            self._countries_preloaded = True

            logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {count} –∑–∞–ø–∏—Å–µ–π —Å—Ç—Ä–∞–Ω –≤ –∫—ç—à –∑–∞ {elapsed:.2f} —Å–µ–∫")
            logger.info(f"   –†–∞–∑–º–µ—Ä –∫—ç—à–∞ —Å—Ç—Ä–∞–Ω: {self._country_cache.size()}/{self._country_cache.maxsize}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ —Å—Ç—Ä–∞–Ω: {e}")
            import traceback

            logger.error(f"–¢—Ä–µ–π—Å–±—ç–∫: {traceback.format_exc()}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏

    async def preload_attribute_types(self):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–∏–ø—ã –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏–∑ –ë–î –≤ –∫—ç—à"""

        logger.info("üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Ç–∏–ø–æ–≤ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏–∑ –ë–î...")

        start_time = asyncio.get_event_loop().time()

        try:
            stmt = select(MetricAttributeTypeModel)
            result = await self._execute_with_retry(stmt)
            attribute_types = result.scalars().all()

            count = 0
            for attr_type in attribute_types:
                self._attribute_type_cache.set(attr_type.code, attr_type)
                count += 1

            elapsed = asyncio.get_event_loop().time() - start_time
            logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {count} —Ç–∏–ø–æ–≤ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –≤ –∫—ç—à –∑–∞ {elapsed:.2f} —Å–µ–∫")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ —Ç–∏–ø–æ–≤ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {e}")

    async def preload_attribute_values(self):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç —á–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤"""

        logger.info("üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∏–∑ –ë–î...")
        start_time = asyncio.get_event_loop().time()

        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            stmt = select(MetricAttributeValueModel)
            result = await self._execute_with_retry(stmt)
            attribute_values = result.scalars().all()

            count = 0
            for attr_value in attribute_values:
                cache_key = self._get_cache_key_for_attribute_value(
                    cast(int, attr_value.attribute_type_id), attr_value.code
                )
                self._attribute_value_cache.set(cache_key, attr_value)
                count += 1

            elapsed = asyncio.get_event_loop().time() - start_time
            logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {count} –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –≤ –∫—ç—à –∑–∞ {elapsed:.2f} —Å–µ–∫")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {e}")

    async def preload_series_for_metric(self, metric_id: int, batch_size: int = 1000):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç —Å–µ—Ä–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""

        logger.info(f"üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ —Å–µ—Ä–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ ID: {metric_id}...")
        start_time = asyncio.get_event_loop().time()
        total_loaded = 0

        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏
            count_stmt = select(func.count(MetricSeriesNewModel.id)).where(MetricSeriesNewModel.metric_id == metric_id)
            count_result = await self._execute_with_retry(count_stmt)
            total_series = count_result.scalar()

            logger.info(f"üìä –í—Å–µ–≥–æ —Å–µ—Ä–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏: {total_series}")

            if total_series == 0:
                logger.info(f"‚úÖ –ù–µ—Ç —Å–µ—Ä–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ {metric_id}")
                return

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—á–∫–∞–º–∏
            offset = 0
            while offset < total_series:
                # –ü–æ–ª—É—á–∞–µ–º –ø–∞—á–∫—É —Å–µ—Ä–∏–π
                stmt = (
                    select(MetricSeriesNewModel)
                    .where(MetricSeriesNewModel.metric_id == metric_id)
                    .order_by(MetricSeriesNewModel.id)
                    .offset(offset)
                    .limit(batch_size)
                )

                result = await self._execute_with_retry(stmt)
                series_list = result.scalars().all()

                if not series_list:
                    break

                # –ü–æ–ª—É—á–∞–µ–º ID –≤—Å–µ—Ö —Å–µ—Ä–∏–π –≤ –ø–∞—á–∫–µ
                series_ids = [series.id for series in series_list]

                # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–∏–π –≤ –ø–∞—á–∫–µ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
                attr_stmt = select(MetricSeriesAttribute).where(MetricSeriesAttribute.series_id.in_(series_ids))
                attr_result = await self._execute_with_retry(attr_stmt)
                all_attributes = attr_result.scalars().all()

                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –ø–æ series_id –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
                attributes_by_series = {}
                for attr in all_attributes:
                    attributes_by_series.setdefault(attr.series_id, []).append(attr)

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å–µ—Ä–∏—é –≤ –ø–∞—á–∫–µ
                for series in series_list:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –µ—â–µ –º–µ—Å—Ç–æ –≤ –∫—ç—à–µ
                    if self._series_cache.size() >= self._series_cache.maxsize:
                        logger.warning(
                            f"‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫—ç—à–∞ ({self._series_cache.maxsize} –∑–∞–ø–∏—Å–µ–π). –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏."
                        )
                        elapsed = asyncio.get_event_loop().time() - start_time
                        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {total_loaded} –∏–∑ {total_series} —Å–µ—Ä–∏–π –∑–∞ {elapsed:.2f} —Å–µ–∫")
                        return

                    # –ü–æ–ª—É—á–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Ä–∏–∏
                    series_attrs = attributes_by_series.get(series.id, [])

                    # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–∞—Ä (type_id, value_id)
                    attr_pairs = []
                    for attr in series_attrs:
                        attr_pairs.append((attr.attribute_type_id, attr.attribute_value_id))

                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –∫–ª—é—á–∞
                    attr_pairs.sort(key=lambda x: (x[0], x[1]))

                    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞
                    attr_parts = [f"{attr_type}:{attr_value}" for attr_type, attr_value in attr_pairs]
                    cache_key = f"series_{metric_id}_{'_'.join(attr_parts)}"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≤ –∫—ç—à–µ
                    if not self._series_cache.get(cache_key):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._series_cache.set(cache_key, series)
                        total_loaded += 1

                offset += batch_size
                logger.info(f"üì¶ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ø–∞—á–∫–∞: {min(offset, total_series)}/{total_series} —Å–µ—Ä–∏–π")

            elapsed = asyncio.get_event_loop().time() - start_time
            logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {total_loaded} —Å–µ—Ä–∏–π –≤ –∫—ç—à –∑–∞ {elapsed:.2f} —Å–µ–∫")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ —Å–µ—Ä–∏–π: {e}")
            import traceback

            logger.error(traceback.format_exc())

    async def preload_periods_for_metric(self, metric_id: int, batch_size: int = 1000):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π"""

        logger.info(f"üîÑ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–∏–æ–¥–æ–≤ –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏ ID: {metric_id}...")
        start_time = asyncio.get_event_loop().time()
        cache_count = 0
        total_periods = 0

        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ—Ä–∏–π –¥–ª—è –º–µ—Ç—Ä–∏–∫–∏
            series_count_stmt = select(func.count(MetricSeriesNewModel.id)).where(
                MetricSeriesNewModel.metric_id == metric_id
            )
            series_count_result = await self._execute_with_retry(series_count_stmt)
            total_series = series_count_result.scalar()

            if total_series == 0:
                logger.info(f"‚úÖ –î–ª—è –º–µ—Ç—Ä–∏–∫–∏ {metric_id} –Ω–µ—Ç —Å–µ—Ä–∏–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫—É –ø–µ—Ä–∏–æ–¥–æ–≤")
                return

            logger.info(f"üìä –í—Å–µ–≥–æ —Å–µ—Ä–∏–π –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–∏–æ–¥–æ–≤: {total_series}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–µ—Ä–∏–∏ –ø–∞—á–∫–∞–º–∏
            offset = 0
            while offset < total_series:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∫—ç—à–∞
                if cache_count >= self._period_cache.maxsize:
                    logger.warning(
                        f"‚ö†Ô∏è  –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫—ç—à–∞ ({self._period_cache.maxsize} –∑–∞–ø–∏—Å–µ–π). –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏."
                    )
                    break

                # –ü–æ–ª—É—á–∞–µ–º –ø–∞—á–∫—É —Å–µ—Ä–∏–π
                series_stmt = (
                    select(MetricSeriesNewModel.id)
                    .where(MetricSeriesNewModel.metric_id == metric_id)
                    .order_by(MetricSeriesNewModel.id)
                    .offset(offset)
                    .limit(batch_size)
                )

                series_result = await self._execute_with_retry(series_stmt)
                series_batch = series_result.all()

                if not series_batch:
                    break

                # –ü–æ–ª—É—á–∞–µ–º ID —Å–µ—Ä–∏–π –∏–∑ –ø–∞—á–∫–∏
                series_ids = [s[0] for s in series_batch]

                # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è —ç—Ç–∏—Ö —Å–µ—Ä–∏–π
                periods_stmt = select(MetricPeriodNewModel).where(MetricPeriodNewModel.series_id.in_(series_ids))
                periods_result = await self._execute_with_retry(periods_stmt)
                periods = periods_result.scalars().all()

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–∏–æ–¥—ã
                for period in periods:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç –∫—ç—à–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏
                    if cache_count >= self._period_cache.maxsize:
                        break

                    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –∫—ç—à–∞ –ø–µ—Ä–∏–æ–¥–æ–≤
                    cache_key = f"{period.series_id}_{period.period_type}_{period.period_year}"
                    if period.period_month:
                        cache_key += f"_{period.period_month}"
                    if period.period_quarter:
                        cache_key += f"_q{period.period_quarter}"
                    if period.period_week:
                        cache_key += f"_w{period.period_week}"

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≤ –∫—ç—à–µ
                    if not self._period_cache.get(cache_key):
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        self._period_cache.set(cache_key, period)
                        cache_count += 1

                    total_periods += 1

                offset += len(series_batch)
                logger.info(
                    f"üì¶ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–µ—Ä–∏–π: {min(offset, total_series)}/{total_series}, "
                    f"–ø–µ—Ä–∏–æ–¥–æ–≤: {total_periods}, –≤ –∫—ç—à: {cache_count}"
                )

                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞—á–∫–∞–º–∏ –¥–ª—è —Ä–∞–∑–≥—Ä—É–∑–∫–∏ –ë–î
                await asyncio.sleep(0.1)

            elapsed = asyncio.get_event_loop().time() - start_time
            logger.info(
                f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {cache_count} –ø–µ—Ä–∏–æ–¥–æ–≤ –≤ –∫—ç—à –∑–∞ {elapsed:.2f} —Å–µ–∫ "
                f"(–≤—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_periods} –ø–µ—Ä–∏–æ–¥–æ–≤)"
            )

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–µ –ø–µ—Ä–∏–æ–¥–æ–≤: {e}")
            import traceback

            logger.error(traceback.format_exc())


async def bulk_insert_metric_data_vectorized(self, records: List[MetricDataNewModel]) -> int:
    """–í–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –º–∞—Å—Å–æ–≤–∞—è –≤—Å—Ç–∞–≤–∫–∞"""

    if not records:
        return 0

    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        import pandas as pd

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
        df = pd.DataFrame(
            [
                {
                    "series_id": r.series_id,
                    "period_id": r.period_id,
                    "country_id": r.country_id,
                    "city_id": r.city_id if r.city_id else None,
                    "value_numeric": r.value_numeric,
                    "value_string": r.value_string,
                    "value_boolean": r.value_boolean,
                    "value_range_start": r.value_range_start,
                    "value_range_end": r.value_range_end,
                    "meta_data": r.meta_data,
                    "created_at": r.created_at,
                    "updated_at": r.updated_at,
                }
                for r in records
            ]
        )

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º pd.io.sql –¥–ª—è –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π –≤—Å—Ç–∞–≤–∫–∏
        from sqlalchemy import create_engine
        import io

        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ DataFrame –≤ CSV
        output = io.StringIO()
        df.to_csv(output, sep="\t", header=False, index=False)
        output.seek(0)

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º COPY FROM –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏
        raw_conn = await self.session.connection()
        cursor = await raw_conn.connection.cursor()

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        await cursor.execute(
            """
            CREATE TEMP TABLE temp_metric_data_copy (
                series_id INTEGER,
                period_id INTEGER,
                country_id INTEGER,
                city_id INTEGER,
                value_numeric NUMERIC,
                value_string VARCHAR,
                value_boolean BOOLEAN,
                value_range_start NUMERIC,
                value_range_end NUMERIC,
                meta_data JSONB,
                created_at TIMESTAMPTZ,
                updated_at TIMESTAMPTZ
            )
        """
        )

        # –ö–æ–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        await cursor.copy_from(output, "temp_metric_data_copy", sep="\t", null="")

        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        await cursor.execute(
            """
            INSERT INTO metric_data_new 
            SELECT * FROM temp_metric_data_copy t
            WHERE NOT EXISTS (
                SELECT 1 FROM metric_data_new m
                WHERE m.series_id = t.series_id
                AND m.country_id = t.country_id
                AND m.period_id = t.period_id
                AND COALESCE(m.city_id, -1) = COALESCE(t.city_id, -1)
            )
        """
        )

        total_inserted = cursor.rowcount
        await cursor.execute("COMMIT")

        return total_inserted

    except Exception as e:
        await self.session.rollback()
        logger.error(f"–û—à–∏–±–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–π –≤—Å—Ç–∞–≤–∫–∏: {e}")
        raise
